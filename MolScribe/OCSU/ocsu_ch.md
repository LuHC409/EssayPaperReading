# 🧬 Optical Chemical Structure Understanding (OCSU) — 论文速读 Part 1

## 一、研究背景与任务定位

### 📌 背景：分子图像是化学文献核心信息载体

- 在药物、材料、生物等研究领域，大量分子信息存在于 **二维结构图像中**。
- 这些图广泛出现在：
  - 专利文献（如 USPTO）
  - 学术期刊（如 ACS）
  - 教科书与数据库资料
- 手动解析这些结构图费时费力，**阻碍了自动化科学发现**。

---

### 🎯 新任务定义：OCSU（Optical Chemical Structure Understanding）

> **OCSU 是一个将分子结构图转化为自然语言或机器可读字符串的图像字幕任务。**

#### 与传统 OCSR 的差异：

| 任务 | 输入 | 输出 | 范围层次 |
|------|------|------|----------|
| OCSR | 图像 | SMILES | 原子级（atom-level） |
| OCSU | 图像 | 多层级文本 | Motif → Molecule → Abstract |

---

### 🧠 OCSU 的四类子任务（分为三个层级）

| 层级            | 子任务类型                           | 输出内容示例                     |
|-----------------|--------------------------------------|----------------------------------|
| **Motif Level** | 功能团字幕 Functional Group Caption  | 酮、羧酸、醇、芳香环等           |
| **Molecule Level** | 分子结构描述 Molecule Description    | “该分子具有抗炎活性...”         |
| **Abstract Level** | IUPAC 命名 / SMILES 命名            | “methyl 2-(4-hydroxyphenyl)...” |

---

## 二、Vis-CheBI20 数据集构建

### 🎯 目标：构建一个用于训练与评估 OCSU 的图文多模态数据集

#### 🧱 基础来源：CheBI20

- 原始 CheBI20 是一个纯文本结构数据集：
  - 包含 SMILES 表达式
  - 分子功能描述（自然语言）
- 本研究使用它作为结构信息的基础。

---

### 🔧 数据构建流程：

1. **图像合成**：利用 RDKit 将 SMILES 渲染为结构图
2. **任务扩展**：
   - 利用 PubChem 查询 SMILES → 获取 IUPAC 名称
   - 规则识别 → 标注功能团信息（59 通用 + 106 环状）
3. **问答生成**：
   - 构造标准任务问题（例如“请列出官能团”、“该分子用于什么？”）
   - 配对答案，形成任务样本

---

### ✅ 数据集结构概览：

| 项目               | 内容与数量说明                                    |
|--------------------|----------------------------------------------------|
| 样本总数           | 约 26,000 条图文样本                                |
| 图像来源           | RDKit 自动渲染                                      |
| 支持任务类型       | 官能团识别 / 分子描述 / IUPAC 命名 / SMILES 生成     |
| 输入格式           | 图像（结构图） + 自然语言指令（prompt）             |
| 输出格式           | 文本（官能团列表 / 结构功能描述 / 命名等）           |

---


## 二、双路径技术方案：OCSR-based vs OCSR-free

---

## 🔴 方法一：OCSR-based 方法 —— Double-Check

### ✅ 总体思路

> 分阶段方法：**图像 → SMILES → 文本**

结构图像先转为 SMILES 结构编码，再接 SMILES-based 模块完成：
- 官能团识别（via RDKit）
- IUPAC 命名（via PubChem 查询）
- 分子描述生成（via BioT5 等）

---

### 🧠 核心技术创新：Double-Check 模块

#### 📌 目标：
提升结构图中 **模糊原子区域的识别准确性**

#### 📍 机制：

1. **模糊原子定位（Local Ambiguity Detection）**
   - 对所有原子预测输出置信度
   - 若置信度 < 0.8 → 标记为模糊区域
   - 利用 2D 高斯掩码遮蔽图像，仅保留模糊区域

2. **局部编码器（Atom-level Encoder）**
   - 使用 Swin-B 网络提取模糊区域特征 `F_l`

3. **全局融合（Local-Global Fusion）**
   - 将模糊区域特征与全图特征 `F_g` 融合，生成增强特征：
     ```
     F_e = F_g + MLP(F_g ⊕ F_l_hat) * F_l_hat
     ```

---

### 🧬 图像到 SMILES 的生成流程：

- **Atom predictor**（原子序列建模）：

  P(A|I) = Π_{i=1}^{n} P(a_i | A_{<i}, I)




- **Bond predictor**（连接矩阵建模）：
P(B|A, I) = Π_{i=1}^{n} Π_{j=1}^{n} P(b_{i,j} | A, I)

- **最终输出 SMILES 表达式**

---

### 🔗 后续模块（SMILES → 文本）：
- 使用工具或模型如：
  - **RDKit**：功能团识别
  - **PubChem API**：IUPAC 命名查询
  - **BioT5 / MoMu**：结构自然语言描述生成

---

## 🔵 方法二：OCSR-free 方法 —— Mol-VL

### ✅ 总体思路

> **端到端方法：结构图像 → 多任务自然语言输出**

Mol-VL 是一个统一的多模态大模型（VLM），支持：
- 官能团字幕（caption）
- 分子结构描述（description）
- IUPAC 命名（naming）

---

### 📐 模型结构：

#### 1️⃣ Vision Encoder（视觉编码器）

- 基础架构：**Vision Transformer (ViT)**
- 图像编码为 patch-level token 序列
- 增强技术：
  - **Naive Dynamic Resolution**：处理不同尺寸图像
  - **Multimodal Rotary Positional Embedding (M-RoPE)**：保留结构相对位置感知能力

#### 2️⃣ Prompt Instruction（任务指令控制）

- 利用 `<image>...</image>` 包裹结构图输入
- 提供自然语言指令，例如：
  ```plaintext
  Please list the functional groups of the molecule.
# 🧬 Optical Chemical Structure Understanding (OCSU) — 论文速读 Part 3

## 三、OCSU 三大子任务：性能分析与实验比较

本节对比分析两种方法在 OCSU 三个核心子任务上的表现：

---

## 🧪 子任务一：Functional Group Caption（官能团识别）

> 📌 目标：从结构图中识别并列出所有官能团（例如羧酸、酮、醚等）

### 📊 实验结果（Table 7）：

| 方法                    | F1 Score | Precision | Recall  |
|-------------------------|----------|-----------|---------|
| MolScribe + RDKit       | 89.60    | 91.88     | 87.87   |
| **Double-Check + RDKit**| 93.63    | 93.58     | 93.90   |
| Mol-VL-2B               | 95.40    | 95.48     | 95.99   |
| **Mol-VL-7B**           | **97.32**| **96.94** | **98.15** |

---

### 🔍 分析与解读：

- **Double-Check** 显著提高了 SMILES 结构识别准确率，因此配合 RDKit 官能团识别效果也显著优于 MolScribe。
- **Mol-VL-7B** 在所有指标上均优于其他模型，说明其通过端到端方式**有效学习了图像中结构模式 → 功能团语义的映射**。
- 官能团是子结构模式，适合被视觉-语言模型整体识别和类比建模。

---

## 📘 子任务二：Molecule Description（分子结构自然语言描述）

> 📌 目标：用自然语言描述分子的结构特点、类别、功能用途等。

### 📊 实验结论（见 Table 6，简化版本）：

| 方法组合                | 效果 |
|-------------------------|------|
| MolScribe + BioT5       | baseline |
| **Double-Check + BioT5**| 平均提升约 +0.81% |
| Mol-VL-2B               | 略低于 baseline |
| **Mol-VL-7B**           | ✅ SOTA 表现 |

---

### 🔍 分析与解读：

- OCSR-based 方法仍依赖结构准确性 → 结构越准确，描述越合理。
- Mol-VL-7B 直接从结构图图像 → 生成完整描述，在描述流畅性与语义丰富性方面明显更强。
- 作者指出：**若训练集更大、图像风格更丰富，Mol-VL 的表现还能进一步提升**。

---

## 🧪 子任务三：IUPAC Naming（化学结构命名）

> 📌 目标：输出该分子的 IUPAC 命名字符串，例如：
> `methyl 2-(4-hydroxyphenyl)...`

### 📊 实验结果（Table 8）：

| 方法                      | BLEU-4 | ROUGE-L | METEOR |
|---------------------------|--------|----------|--------|
| MolScribe + PubChemDB     | 61.03  | 82.68    | 82.70  |
| **Double-Check + PubChem**| 64.23  | **84.40**| **84.47** |
| Mol-VL-2B                 | 72.79  | 77.67    | 77.76  |
| **Mol-VL-7B**             | **76.95**| 77.69    | 81.72  |

---

### 📌 指标说明：

- **BLEU**：强调短语匹配（生成准确度） → Mol-VL 更优
- **ROUGE**：强调覆盖率（召回率） → Double-Check 更高
- **METEOR**：综合语言生成能力 → Mol-VL-7B 最平衡

---

### 🔍 分析与解读：

- OCSR-based 方法更适合于精确查库 → 高 recall
- Mol-VL 更擅长语言生成 → 高 BLEU，适合人类阅读和教学展示
- 作者建议：未来可采用**集成方法**融合两者优势（准确 + 表达）

---

## 🔬 附加指标：SMILES 结构识别性能

| 指标       | 提升幅度（Double-Check 相比 MolScribe） |
|------------|------------------------------------------|
| Acc<sub>s</sub> | +1.97%                                   |
| Acc<sub>g</sub> | +2.70%                                   |
| Acc<sub>c</sub> | +2.49%                                   |
| Tanimoto    | +1.91%                                   |

✅ 说明 Double-Check 是目前结构图识别最鲁棒、最准确的方法之一。

---


## 四、方法总结、应用建议与未来展望

---

## ✅ 方法比较总结（论文主张）

| 维度                     | OCSR-based（Double-Check）                 | OCSR-free（Mol-VL）                        |
|--------------------------|--------------------------------------------|--------------------------------------------|
| 是否端到端               | ❌ 分阶段                                   | ✅ 端到端                                 |
| 是否生成 SMILES          | ✅ 是                                       | ❌ 否（直接图像→文本）                      |
| 可解释性 / 可追踪性       | ✅ 高（每一步可见、可调、可查）              | 较低（语言生成结果不可控性更高）             |
| 自然语言表达能力         | 中（需 SMILES + NLP 模块）                 | ✅ 强（直接生成自然语言输出）                |
| 官能团识别能力           | 高（RDKit 支持）                           | ✅ 更高（结构上下文直接建模）                |
| 分子功能描述能力         | 一般（依赖结构准确）                       | ✅ SOTA（Mol-VL-7B）                       |
| IUPAC 命名精度           | ✅ 更强 recall（查库更全）                  | ✅ 更强 precision（句子更自然）              |
| 模型组合方式             | 多模块（结构识别 + 结构分析 + 文本生成）    | 一个模型 + 多任务 prompt                   |
| 适合场景                 | 数据驱动建库、化学检索、合成规划、图重建     | 教学讲解、结构问答、写作辅助、多模态展示      |

---

## 🧭 应用建议：根据目标任务选择方法

| 应用目标                       | 推荐方法                        | 原因说明                                     |
|--------------------------------|----------------------------------|----------------------------------------------|
| 结构重建 / 编辑 / 分子设计     | ✅ Double-Check                | SMILES 输出稳定，可接其他结构工具链              |
| 教学辅助 / 图像问答            | ✅ Mol-VL-7B                   | 指令控制灵活、回答自然、结构理解通顺              |
| 图像批量命名 / 标准化入库       | Double-Check + PubChem         | 精确调用现有命名系统                           |
| 自然语言报告生成 / 教学材料编写 | Mol-VL-7B                      | 可结合描述 + 命名 + 官能团整合成段落               |
| 多模态 QA 助理 / ChatChem      | Mol-VL-7B（或后续微调版本）     | 支持指令、对话、视觉问答三合一                    |

---

## 📈 实验综合结论一句话总结：

> **Double-Check 是当前结构识别最强的图像→SMILES 模型；Mol-VL-7B 是目前结构图自然语言理解最强的模型。**

两者分别代表：
- 结构精度导向型系统
- 多任务语言理解型系统

---

## 🔬 第七章：局限与未来工作（Limitation & Future Work）

---

### ⚠️ 限制 1：Vis-CheBI20 数据集为“合成图像”

- 图像由 RDKit 渲染，风格较“标准化”
- 与现实中的专利图、扫描图、手绘图有明显差异

#### 🔧 改进方向：
- 构建真实图像组成的数据集
- 覆盖多种风格、分辨率、含文本干扰、模糊边缘等情况

---

### ⚠️ 限制 2：未支持 Markush 结构表示

- Markush 是专利中用于表达“结构变量”的泛式结构，如：
R1 = OH / NH2 / CH3

#### 🔧 改进方向：
- 融合图像结构识别与图结构语言理解
- 构建结构变量解析模块（或泛结构预测模型）

---

## 🧠 延伸思考（适合教学/研究者）

- 多轮结构图问答系统设计（“它包含哪些官能团？”→“这些官能团有什么作用？”）
- 图像 + 文献文字联合模型（视觉结构 + 文本摘要一体）
- 用 LLM 编写多语言解释（中英双语分子讲解）
- 化学图文风格迁移训练（增强模型泛化到期刊 / 专利 / 手绘结构图）

---

## 📚 全文总结一句话：

> 本文首次提出 OCSU 任务，构建 Vis-CheBI20 数据集，并通过 OCSR-based（Double-Check）与 OCSR-free（Mol-VL）两个方向，构建并验证结构图像理解的新一代方法，在图像化学理解的多个核心子任务中实现了 SOTA 性能，开启了分子多模态理解的新篇章。

---

